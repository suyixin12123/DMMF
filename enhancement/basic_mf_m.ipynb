{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Global values\n",
    "\"\"\"\n",
    "FEATURE_LEN = 5\n",
    "folder = 'boxoffice_10'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training number:  79460\n",
      "validaton number:  9933\n",
      "test number:  9933\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_rating = pickle.load(open('../data/'+folder+'/user_rating.pkl', 'rb'))\n",
    "\n",
    "user_rating_valid = pickle.load(open('../data/'+folder+'/user_rating_validation.pkl', 'rb'))\n",
    "\n",
    "user_rating_test = pickle.load(open('../data/'+folder+'/user_rating_test.pkl', 'rb'))\n",
    "\n",
    "df_train = []\n",
    "max_user = 0\n",
    "max_movie = 0\n",
    "for user in user_rating:\n",
    "    user_i = int(user)\n",
    "    for tup in user_rating[user]:\n",
    "        rating_i = float(tup[1])\n",
    "        movie_i = int(tup[0])\n",
    "        #user_list.append(user_i)\n",
    "        #movie_list.append(movie_i)\n",
    "        #rating_list.append(float(rating_i))\n",
    "        df_train.append([user_i, movie_i, float(rating_i)])\n",
    "        if movie_i > max_movie:\n",
    "            max_movie = movie_i\n",
    "    \n",
    "    if user_i > max_user:\n",
    "        max_user = user_i\n",
    "        \n",
    "df_test = []\n",
    "for user in user_rating_test:\n",
    "    user_i = int(user)\n",
    "    for tup in user_rating_test[user]:\n",
    "        rating_i = float(tup[1])\n",
    "        movie_i = int(tup[0])\n",
    "        #user_list.append(user_i)\n",
    "        #movie_list.append(movie_i)\n",
    "        #rating_list.append(float(rating_i))\n",
    "        df_test.append([user_i, movie_i, float(rating_i)])\n",
    "        if movie_i > max_movie:\n",
    "            max_movie = movie_i\n",
    "    \n",
    "    if user_i > max_user:\n",
    "        max_user = user_i\n",
    "        \n",
    "\n",
    "df_valid = []\n",
    "for user in user_rating_valid:\n",
    "    user_i = int(user)\n",
    "    for tup in user_rating_valid[user]:\n",
    "        rating_i = float(tup[1])\n",
    "        movie_i = int(tup[0])\n",
    "        #user_list.append(user_i)\n",
    "        #movie_list.append(movie_i)\n",
    "        #rating_list.append(float(rating_i))\n",
    "        df_valid.append([user_i, movie_i, float(rating_i)])\n",
    "        if movie_i > max_movie:\n",
    "            max_movie = movie_i\n",
    "    \n",
    "    if user_i > max_user:\n",
    "        max_user = user_i\n",
    "\n",
    "#user_s, movie_s, rating_s = shuffle(user_list, movie_list, rating_list)\n",
    "\n",
    "#df_train, df_test = train_test_split(df, test_size = 0.2)\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "user_s = [t[0] for t in df_train]\n",
    "movie_s = [t[1] for t in df_train]\n",
    "rating_s = [t[2] for t in df_train]\n",
    "\n",
    "user_s_test = [t[0] for t in df_test]\n",
    "movie_s_test = [t[1] for t in df_test]\n",
    "rating_s_test = [t[2] for t in df_test]\n",
    "\n",
    "user_s_valid = [t[0] for t in df_valid]\n",
    "movie_s_valid = [t[1] for t in df_valid]\n",
    "rating_s_valid = [t[2] for t in df_valid]\n",
    "\n",
    "print(\"training number: \", len(user_s))\n",
    "print(\"validaton number: \", len(user_s_valid))\n",
    "print(\"test number: \", len(user_s_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_indecies_train = user_s\n",
    "item_indecies_train = movie_s\n",
    "rates_train = rating_s\n",
    "\n",
    "user_indecies_test = user_s_test\n",
    "item_indecies_test = movie_s_test\n",
    "rates_test = rating_s_test\n",
    "\n",
    "user_indecies_valid = user_s_valid\n",
    "item_indecies_valid = movie_s_valid\n",
    "rates_valid = rating_s_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79460"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totle_len = len(user_s)\n",
    "totle_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max user: 3549\n",
      "max movie: 206\n",
      "[2.0, 3.0, 4.0, 4.0, 3.5, 4.0, 3.0, 3.5, 2.0, 3.5]\n",
      "3550 207\n"
     ]
    }
   ],
   "source": [
    "def get_bias(user, movie, rating):\n",
    "    print('max user:', max_user)\n",
    "    print('max movie:', max_movie)\n",
    "    average = np.mean(rating)\n",
    "    user_dict = {}\n",
    "    movie_dict = {}\n",
    "    for i in range(len(user)):\n",
    "        user_dict[user[i]] = [rating[i]] if user[i] not in user_dict else user_dict[user[i]] + [rating[i]]\n",
    "        movie_dict[movie[i]] = [rating[i]] if movie[i] not in movie_dict else movie_dict[movie[i]] + [rating[i]]\n",
    "    \n",
    "    user_bias = [0 for i in range(max_user + 1)]\n",
    "    movie_bias = [0 for i in range(max_movie + 1)]\n",
    "    print(user_dict[2253])\n",
    "    print(len(user_bias), len(movie_bias))\n",
    "    for key in user_dict:\n",
    "        user_bias[int(key)] = np.mean(user_dict[key]) - average\n",
    "    for key in movie_dict:\n",
    "        movie_bias[int(key)] = np.mean(movie_dict[key]) - average\n",
    "    \n",
    "    return user_bias, movie_bias, average\n",
    "\n",
    "user_bias, movie_bias, average_score = get_bias(user_s, movie_s, rating_s)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_bias_r = np.reshape(user_bias,[-1,1])\n",
    "movie_bias_r = np.reshape(movie_bias,[1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "U = tf.Variable(initial_value=tf.truncated_normal([max_user+1, FEATURE_LEN], stddev=0.2, mean=0), name='users')\n",
    "P = tf.Variable(initial_value=tf.truncated_normal([FEATURE_LEN, max_movie+1], stddev=0.2, mean=0), name='movies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "U_plus_bias = tf.concat([U, tf.constant(user_bias_r, dtype=tf.float32, name=\"user_bias\"), tf.ones((max_user+1,1), dtype=tf.float32, name=\"user_bias_ones\")], 1)\n",
    "P_plus_bias = tf.concat([P, tf.ones((1, max_movie+1), name=\"movie_bias_ones\", dtype=tf.float32), tf.constant(movie_bias_r, dtype=tf.float32, name=\"movie_bias\")], 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#result = tf.matmul(U_plus_bias, P_plus_bias)\n",
    "result = tf.matmul(U, P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_flatten = tf.reshape(result, [-1])\n",
    "R = tf.gather(result_flatten, user_s * tf.shape(result)[1] + movie_s, name='extracting_user_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diff_op = tf.subtract(R, rating_s, name='trainig_diff')\n",
    "diff_op_squared = tf.nn.l2_loss(diff_op, name=\"squared_difference\")\n",
    "base_cost = tf.reduce_sum(diff_op_squared, name=\"sum_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda = tf.constant(0.001, name='lambda')\n",
    "norm_sums = tf.add(tf.reduce_sum(tf.nn.l2_loss(U, name='user_abs'), name='user_norm'), \n",
    "   tf.reduce_sum(tf.nn.l2_loss(P, name='item_abs'), name='item_norm'))\n",
    "regularizer = tf.multiply(norm_sums, lda, 'regularizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.add(base_cost, regularizer)\n",
    "#cost = base_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = tf.constant(.0001, name='learning_rate')\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "learning_rate = tf.train.exponential_decay(lr, global_step, 10000, 0.98, staircase=True)\n",
    "#learning_rate = 0.01\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "training_step = optimizer.minimize(cost, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# accuracy\n",
    "R_test = tf.gather(result_flatten, user_indecies_train * tf.shape(result)[1] + item_indecies_train, name='extracting_user_rate_test')\n",
    "#R_test = tf.cast(R_test, tf.float64)\n",
    "rmse = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(rates_train, R_test))))\n",
    "#print(sess.run(rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in user_indecies_train:\n",
    "    if i < 0:\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# accuracy\n",
    "test_R_test = tf.gather(result_flatten, user_indecies_test * tf.shape(result)[1] + item_indecies_test, name='extracting_user_rate_test')\n",
    "#test_R_test = tf.cast(test_R_test, tf.float64)\n",
    "test_rmse = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(rates_test, test_R_test))))\n",
    "#print(sess.run(rmse))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# accuracy\n",
    "valid_R_test = tf.gather(result_flatten, user_indecies_valid * tf.shape(result)[1] + item_indecies_valid, name='extracting_user_rate_valid')\n",
    "#test_R_test = tf.cast(test_R_test, tf.float64)\n",
    "valid_rmse = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(rates_valid, valid_R_test))))\n",
    "#print(sess.run(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 520576.0 3.61978 3.63133 3.60875 0\n",
      "20 519902.0 3.61744 3.63115 3.60857 0\n",
      "40 518139.0 3.6113 3.62749 3.60478 1\n",
      "60 507863.0 3.57531 3.59594 3.5726 0\n",
      "80 444549.0 3.34503 3.3801 3.35401 0\n",
      "100 250998.0 2.51348 2.58383 2.55525 0\n",
      "120 111366.0 1.67423 1.75803 1.74078 0\n",
      "140 62032.1 1.24952 1.3287 1.31871 0\n",
      "160 42301.7 1.03183 1.1033 1.09657 0\n",
      "180 33243.8 0.914703 0.979419 0.974872 0\n",
      "200 28578.4 0.848087 0.907945 0.905227 0\n",
      "220 25928.7 0.807811 0.864484 0.863355 0\n",
      "240 24292.8 0.781907 0.836618 0.836856 0\n",
      "260 23209.5 0.764272 0.817842 0.819232 0\n",
      "280 22450.0 0.751662 0.804628 0.806978 0\n",
      "300 21892.4 0.742267 0.794982 0.798119 0\n",
      "320 21467.6 0.735029 0.787725 0.791503 0\n",
      "340 21134.2 0.729297 0.782128 0.786425 0\n",
      "360 20865.9 0.724652 0.777723 0.78244 0\n",
      "380 20645.3 0.720811 0.774198 0.779252 0\n",
      "400 20460.6 0.717577 0.771334 0.776661 0\n",
      "420 20303.2 0.714813 0.76898 0.774529 0\n",
      "440 20167.1 0.712413 0.767022 0.772753 0\n",
      "460 20047.7 0.710299 0.765379 0.771261 0\n",
      "480 19941.3 0.708412 0.763987 0.769996 0\n",
      "500 19845.5 0.706708 0.762798 0.768915 0\n",
      "520 19758.0 0.705147 0.761775 0.767987 0\n",
      "540 19677.1 0.703703 0.760888 0.767185 0\n",
      "560 19601.6 0.70235 0.760114 0.766488 1\n",
      "580 19530.3 0.701072 0.759436 0.765881 0\n",
      "600 19462.4 0.699851 0.758837 0.765349 1\n",
      "620 19397.1 0.698677 0.758305 0.764882 0\n",
      "640 19333.9 0.697537 0.757831 0.764472 1\n",
      "660 19272.1 0.696422 0.757406 0.76411 0\n",
      "680 19211.6 0.695326 0.757024 0.76379 1\n",
      "700 19151.7 0.694242 0.75668 0.763508 2\n",
      "720 19092.3 0.693165 0.756368 0.763259 0\n",
      "740 19033.2 0.69209 0.756085 0.763039 1\n",
      "760 18974.1 0.691015 0.755827 0.762846 2\n",
      "780 18914.9 0.689935 0.755593 0.762677 3\n",
      "800 18855.5 0.688851 0.75538 0.76253 0\n",
      "820 18795.7 0.687757 0.755186 0.762403 1\n",
      "840 18735.5 0.686654 0.75501 0.762294 2\n",
      "860 18674.8 0.68554 0.754851 0.762203 3\n",
      "880 18613.5 0.684416 0.754707 0.762128 4\n",
      "900 18551.7 0.683278 0.754578 0.762069 5\n",
      "920 18489.4 0.68213 0.754463 0.762025 0\n",
      "940 18426.6 0.680968 0.754362 0.761995 1\n",
      "960 18363.2 0.679796 0.754274 0.761978 2\n",
      "980 18299.4 0.678614 0.754198 0.761975 3\n",
      "1000 18235.1 0.67742 0.754135 0.761986 4\n",
      "1020 18170.4 0.676217 0.754083 0.762009 5\n",
      "1040 18105.4 0.675007 0.754044 0.762044 6\n",
      "1060 18040.1 0.673788 0.754015 0.762092 7\n",
      "1080 17974.6 0.672563 0.753997 0.762153 8\n",
      "1100 17908.9 0.671333 0.75399 0.762225 9\n",
      "1120 17843.1 0.670097 0.753994 0.762308 10\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "minVR = 999\n",
    "not_change_n = 0\n",
    "for i in range(10001):\n",
    "    _, c, r, tr, vr = sess.run([training_step, cost, rmse, test_rmse, valid_rmse])\n",
    "    if i%20 == 0:\n",
    "        print(i, c, r, vr, tr, not_change_n)\n",
    "    \n",
    "        if vr + 0.001 < minVR:\n",
    "            minVR = vr\n",
    "            not_change_n = 0\n",
    "        else:\n",
    "            not_change_n += 1\n",
    "\n",
    "        if not_change_n > 10:\n",
    "            break\n",
    "            \n",
    "    \n",
    "    \"\"\"\n",
    "    if i%500 == 0:\n",
    "        r, tr = sess.run([rmse, test_rmse])\n",
    "        #r = sess.run([rmse])\n",
    "        print(\"rmse:\", i, r, tr)\n",
    "    \"\"\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.499064\n",
      "0.561465\n",
      "0.565209\n"
     ]
    }
   ],
   "source": [
    "train_mae = tf.reduce_mean(tf.abs(tf.subtract(rates_train, R_test)))\n",
    "test_mae = tf.reduce_mean(tf.abs(tf.subtract(rates_test, test_R_test)))\n",
    "valid_mae = tf.reduce_mean(tf.abs(tf.subtract(rates_valid, valid_R_test)))\n",
    "mae_tr, mae_v, mae_t = sess.run([train_mae, valid_mae, test_mae])\n",
    "print(mae_tr)\n",
    "print(mae_v)\n",
    "print(mae_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_rating = pickle.load(open('../data/'+folder+'/movie_rating.pkl', 'rb'))\n",
    "movie_rating_test = pickle.load(open('../data/'+folder+'/movie_rating_test.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_U, _P, _result = sess.run([U,P, result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "_p = np.transpose(_P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_not_in = 0\n",
    "vv_predict = []\n",
    "vv_y = []\n",
    "largest_num = 10\n",
    "_RMSE_list = []\n",
    "for largest_num in range(0,200, 3): \n",
    "    for m in range(0, max_movie+1):\n",
    "        if (m not in movie_rating or len(movie_rating[m]) <=largest_num) and m in movie_rating_test:\n",
    "            #print('not in', m)\n",
    "            #print(movie_rating_test[m])\n",
    "            for pair in movie_rating_test[m]:\n",
    "                movie_n = m\n",
    "                user_n = pair[0]\n",
    "                vv_predict.append(np.dot(_U[user_n], _p[movie_n]))\n",
    "                vv_y.append(pair[1])\n",
    "            total_not_in += len(movie_rating_test[m])\n",
    "\n",
    "    _RMSE = np.sqrt(np.mean(np.square(np.subtract(vv_predict, vv_y))))\n",
    "    _RMSE_list.append((largest_num, _RMSE))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23916"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_not_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87263121712097491"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.mean(np.square(np.subtract(vv_predict, vv_y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.88079619, 1.7541928, 2.1570361, -3.3290749)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_P[0][0], _P[1][0], _P[2][0], _P[3][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.88079619,  1.75419283,  2.15703607, -3.32907486,  0.43785998], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 3.8032438158988953),\n",
       " (3, 3.8032438158988953),\n",
       " (6, 3.8032438158988957),\n",
       " (9, 3.8032438158988953),\n",
       " (12, 2.9162890541691171),\n",
       " (15, 2.2713762384744887),\n",
       " (18, 1.8895044658938838),\n",
       " (21, 1.672133805068615),\n",
       " (24, 1.5720587660783232),\n",
       " (27, 1.4827465363242989),\n",
       " (30, 1.4305947019386607),\n",
       " (33, 1.3754494515190032),\n",
       " (36, 1.3400730710855555),\n",
       " (39, 1.3021144395383892),\n",
       " (42, 1.2657075130252828),\n",
       " (45, 1.2294875932708178),\n",
       " (48, 1.1970791457934333),\n",
       " (51, 1.172476271682438),\n",
       " (54, 1.1511278975697987),\n",
       " (57, 1.1337542923158619),\n",
       " (60, 1.1138781681230741),\n",
       " (63, 1.0949396026507185),\n",
       " (66, 1.0783737151904815),\n",
       " (69, 1.0653020057905134),\n",
       " (72, 1.0508332384108132),\n",
       " (75, 1.0390618349988823),\n",
       " (78, 1.0272608975674333),\n",
       " (81, 1.0173894384944819),\n",
       " (84, 1.0090089112533789),\n",
       " (87, 0.99975163003232959),\n",
       " (90, 0.99001291879616082),\n",
       " (93, 0.98126866430302329),\n",
       " (96, 0.97212233046435514),\n",
       " (99, 0.96283689479719325),\n",
       " (102, 0.95455102700687267),\n",
       " (105, 0.94653573689480153),\n",
       " (108, 0.93883103363880505),\n",
       " (111, 0.93197386438820351),\n",
       " (114, 0.92571575179178534),\n",
       " (117, 0.91998212638511123),\n",
       " (120, 0.91498123190059999),\n",
       " (123, 0.91058085906272324),\n",
       " (126, 0.90667883684339767),\n",
       " (129, 0.90319495168818786),\n",
       " (132, 0.90083762311588023),\n",
       " (135, 0.899103594214821),\n",
       " (138, 0.89742824423036693),\n",
       " (141, 0.89581760275088673),\n",
       " (144, 0.89436854220713902),\n",
       " (147, 0.89305790415059294),\n",
       " (150, 0.89186675470401233),\n",
       " (153, 0.89077946310883227),\n",
       " (156, 0.88946304561787637),\n",
       " (159, 0.88826055300332241),\n",
       " (162, 0.88715780687488921),\n",
       " (165, 0.88606825537509593),\n",
       " (168, 0.88470298822591831),\n",
       " (171, 0.88344523331091507),\n",
       " (174, 0.88172612471499934),\n",
       " (177, 0.88010611222487389),\n",
       " (180, 0.87860787631201298),\n",
       " (183, 0.87721817756748766),\n",
       " (186, 0.87621663121248061),\n",
       " (189, 0.87528624747982553),\n",
       " (192, 0.87441970070312436),\n",
       " (195, 0.87349424711278623),\n",
       " (198, 0.87263121712097491)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_RMSE_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('MF_RMSE.csv','w') as f:\n",
    "    f_csv = csv.writer(f)\n",
    "    headers = ['num, RMSE']\n",
    "    f_csv.writerow(headers)\n",
    "    for p in _RMSE_list:\n",
    "        row = [p[0], p[1]]\n",
    "        f_csv.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ws3.6",
   "language": "python",
   "name": "ws"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
