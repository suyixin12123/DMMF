{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Global values\n",
    "\"\"\"\n",
    "FEATURE_LEN = 20\n",
    "folder = 'year2010_movie'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training number:  201623\n",
      "validaton number:  25203\n",
      "test number:  25203\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_rating = pickle.load(open('../data/'+folder+'/user_rating.pkl', 'rb'))\n",
    "\n",
    "user_rating_valid = pickle.load(open('../data/'+folder+'/user_rating_validation.pkl', 'rb'))\n",
    "\n",
    "user_rating_test = pickle.load(open('../data/'+folder+'/user_rating_test.pkl', 'rb'))\n",
    "\n",
    "df_train = []\n",
    "max_user = 0\n",
    "max_movie = 0\n",
    "for user in user_rating:\n",
    "    user_i = int(user)\n",
    "    for tup in user_rating[user]:\n",
    "        rating_i = float(tup[1])\n",
    "        movie_i = int(tup[0])\n",
    "        #user_list.append(user_i)\n",
    "        #movie_list.append(movie_i)\n",
    "        #rating_list.append(float(rating_i))\n",
    "        df_train.append([user_i, movie_i, float(rating_i)])\n",
    "        if movie_i > max_movie:\n",
    "            max_movie = movie_i\n",
    "    \n",
    "    if user_i > max_user:\n",
    "        max_user = user_i\n",
    "        \n",
    "df_test = []\n",
    "for user in user_rating_test:\n",
    "    user_i = int(user)\n",
    "    for tup in user_rating_test[user]:\n",
    "        rating_i = float(tup[1])\n",
    "        movie_i = int(tup[0])\n",
    "        #user_list.append(user_i)\n",
    "        #movie_list.append(movie_i)\n",
    "        #rating_list.append(float(rating_i))\n",
    "        df_test.append([user_i, movie_i, float(rating_i)])\n",
    "        if movie_i > max_movie:\n",
    "            max_movie = movie_i\n",
    "    \n",
    "    if user_i > max_user:\n",
    "        max_user = user_i\n",
    "        \n",
    "\n",
    "df_valid = []\n",
    "for user in user_rating_valid:\n",
    "    user_i = int(user)\n",
    "    for tup in user_rating_valid[user]:\n",
    "        rating_i = float(tup[1])\n",
    "        movie_i = int(tup[0])\n",
    "        #user_list.append(user_i)\n",
    "        #movie_list.append(movie_i)\n",
    "        #rating_list.append(float(rating_i))\n",
    "        df_valid.append([user_i, movie_i, float(rating_i)])\n",
    "        if movie_i > max_movie:\n",
    "            max_movie = movie_i\n",
    "    \n",
    "    if user_i > max_user:\n",
    "        max_user = user_i\n",
    "\n",
    "#user_s, movie_s, rating_s = shuffle(user_list, movie_list, rating_list)\n",
    "\n",
    "#df_train, df_test = train_test_split(df, test_size = 0.2)\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "user_s = [t[0] for t in df_train]\n",
    "movie_s = [t[1] for t in df_train]\n",
    "rating_s = [t[2] for t in df_train]\n",
    "\n",
    "user_s_test = [t[0] for t in df_test]\n",
    "movie_s_test = [t[1] for t in df_test]\n",
    "rating_s_test = [t[2] for t in df_test]\n",
    "\n",
    "user_s_valid = [t[0] for t in df_valid]\n",
    "movie_s_valid = [t[1] for t in df_valid]\n",
    "rating_s_valid = [t[2] for t in df_valid]\n",
    "\n",
    "print(\"training number: \", len(user_s))\n",
    "print(\"validaton number: \", len(user_s_valid))\n",
    "print(\"test number: \", len(user_s_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_indecies_train = user_s\n",
    "item_indecies_train = movie_s\n",
    "rates_train = rating_s\n",
    "\n",
    "user_indecies_test = user_s_test\n",
    "item_indecies_test = movie_s_test\n",
    "rates_test = rating_s_test\n",
    "\n",
    "user_indecies_valid = user_s_valid\n",
    "item_indecies_valid = movie_s_valid\n",
    "rates_valid = rating_s_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3906"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201623"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totle_len = len(user_s)\n",
    "totle_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max user: 3838\n",
      "max movie: 3906\n",
      "[3.5, 3.0, 4.0, 4.0, 4.0, 4.5, 4.0, 2.0, 4.5, 4.0, 2.0, 4.0, 4.5, 4.0, 4.0, 4.0, 4.0, 4.0, 2.0]\n",
      "3839 3907\n"
     ]
    }
   ],
   "source": [
    "def get_bias(user, movie, rating):\n",
    "    print('max user:', max_user)\n",
    "    print('max movie:', max_movie)\n",
    "    average = np.mean(rating)\n",
    "    user_dict = {}\n",
    "    movie_dict = {}\n",
    "    for i in range(len(user)):\n",
    "        user_dict[user[i]] = [rating[i]] if user[i] not in user_dict else user_dict[user[i]] + [rating[i]]\n",
    "        movie_dict[movie[i]] = [rating[i]] if movie[i] not in movie_dict else movie_dict[movie[i]] + [rating[i]]\n",
    "    \n",
    "    user_bias = [0 for i in range(max_user + 1)]\n",
    "    movie_bias = [0 for i in range(max_movie + 1)]\n",
    "    print(user_dict[2253])\n",
    "    print(len(user_bias), len(movie_bias))\n",
    "    for key in user_dict:\n",
    "        user_bias[int(key)] = np.mean(user_dict[key]) - average\n",
    "    for key in movie_dict:\n",
    "        movie_bias[int(key)] = np.mean(movie_dict[key]) - average\n",
    "    \n",
    "    return user_bias, movie_bias, average\n",
    "\n",
    "user_bias, movie_bias, average_score = get_bias(user_s, movie_s, rating_s)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_bias_r = np.reshape(user_bias,[-1,1])\n",
    "movie_bias_r = np.reshape(movie_bias,[1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "U = tf.Variable(initial_value=tf.truncated_normal([max_user+1, FEATURE_LEN], stddev=0.2, mean=0), name='users')\n",
    "P = tf.Variable(initial_value=tf.truncated_normal([FEATURE_LEN, max_movie+1], stddev=0.2, mean=0), name='movies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "U_plus_bias = tf.concat([U, tf.constant(user_bias_r, dtype=tf.float32, name=\"user_bias\"), tf.ones((max_user+1,1), dtype=tf.float32, name=\"user_bias_ones\")], 1)\n",
    "P_plus_bias = tf.concat([P, tf.ones((1, max_movie+1), name=\"movie_bias_ones\", dtype=tf.float32), tf.constant(movie_bias_r, dtype=tf.float32, name=\"movie_bias\")], 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#result = tf.matmul(U_plus_bias, P_plus_bias)\n",
    "result = tf.matmul(U, P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_flatten = tf.reshape(result, [-1])\n",
    "R = tf.gather(result_flatten, user_s * tf.shape(result)[1] + movie_s, name='extracting_user_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diff_op = tf.subtract(R, rating_s, name='trainig_diff')\n",
    "diff_op_squared = tf.nn.l2_loss(diff_op, name=\"squared_difference\")\n",
    "base_cost = tf.reduce_sum(diff_op_squared, name=\"sum_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda = tf.constant(0.001, name='lambda')\n",
    "norm_sums = tf.add(tf.reduce_sum(tf.nn.l2_loss(U, name='user_abs'), name='user_norm'), \n",
    "   tf.reduce_sum(tf.nn.l2_loss(P, name='item_abs'), name='item_norm'))\n",
    "regularizer = tf.multiply(norm_sums, lda, 'regularizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clip_U = U.assign(tf.maximum(tf.zeros_like(U), U))\n",
    "clip_P = P.assign(tf.maximum(tf.zeros_like(P), P))\n",
    "clip = tf.group(clip_U, clip_P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.add(base_cost, regularizer)\n",
    "#cost = base_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = tf.constant(.0001, name='learning_rate')\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "learning_rate = tf.train.exponential_decay(lr, global_step, 10000, 0.98, staircase=True)\n",
    "#learning_rate = 0.01\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "training_step = optimizer.minimize(cost, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# accuracy\n",
    "R_test = tf.gather(result_flatten, user_indecies_train * tf.shape(result)[1] + item_indecies_train, name='extracting_user_rate_test')\n",
    "#R_test = tf.cast(R_test, tf.float64)\n",
    "rmse = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(rates_train, R_test))))\n",
    "#print(sess.run(rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in user_indecies_train:\n",
    "    if i < 0:\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# accuracy\n",
    "test_R_test = tf.gather(result_flatten, user_indecies_test * tf.shape(result)[1] + item_indecies_test, name='extracting_user_rate_test')\n",
    "#test_R_test = tf.cast(test_R_test, tf.float64)\n",
    "test_rmse = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(rates_test, test_R_test))))\n",
    "#print(sess.run(rmse))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# accuracy\n",
    "valid_R_test = tf.gather(result_flatten, user_indecies_valid * tf.shape(result)[1] + item_indecies_valid, name='extracting_user_rate_valid')\n",
    "#test_R_test = tf.cast(test_R_test, tf.float64)\n",
    "valid_rmse = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(rates_valid, valid_R_test))))\n",
    "#print(sess.run(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.29791e+06 3.58812 3.59437 3.58403 0\n",
      "20 633931.0 2.50764 2.52474 2.51376 0\n",
      "40 298321.0 1.72022 1.73898 1.74205 0\n",
      "60 202012.0 1.41556 1.43885 1.44342 0\n",
      "80 158655.0 1.25448 1.28131 1.28641 0\n",
      "100 134681.0 1.15581 1.18528 1.19068 0\n",
      "120 119535.0 1.08888 1.12051 1.12615 0\n",
      "140 109072.0 1.04013 1.07365 1.07954 0\n",
      "160 101383.0 1.0028 1.03801 1.04416 0\n",
      "180 95472.1 0.97312 1.00989 1.01629 0\n",
      "200 90768.8 0.948845 0.987066 0.9937 0\n",
      "220 86924.1 0.928529 0.968118 0.974969 0\n",
      "240 83711.8 0.911207 0.952107 0.959153 0\n",
      "260 80978.6 0.896208 0.938378 0.945594 0\n",
      "280 78617.0 0.883042 0.926465 0.933823 0\n",
      "300 76549.5 0.871351 0.91602 0.923499 0\n",
      "320 74718.4 0.860863 0.906783 0.914363 0\n",
      "340 73080.2 0.851374 0.89855 0.906213 0\n",
      "360 71600.7 0.842709 0.891168 0.898895 0\n",
      "380 70253.2 0.83474 0.884509 0.892283 0\n",
      "400 69016.9 0.827361 0.878469 0.886284 0\n",
      "420 67873.7 0.820478 0.87296 0.880805 0\n",
      "440 66810.5 0.814026 0.867919 0.875784 0\n",
      "460 65814.5 0.807935 0.863284 0.871162 0\n",
      "480 64875.6 0.802149 0.859007 0.866888 0\n",
      "500 63985.5 0.796627 0.855045 0.862922 0\n",
      "520 63137.1 0.791326 0.851361 0.859228 0\n",
      "540 62324.3 0.786215 0.847931 0.855778 0\n",
      "560 61542.6 0.781268 0.844727 0.852553 0\n",
      "580 60787.6 0.776459 0.841727 0.84952 0\n",
      "600 60055.8 0.77177 0.83891 0.846665 0\n",
      "620 59344.9 0.767188 0.836253 0.84398 0\n",
      "640 58652.7 0.762699 0.833749 0.841448 0\n",
      "660 57977.5 0.758296 0.831388 0.839058 0\n",
      "680 57316.9 0.753963 0.829159 0.836804 0\n",
      "700 56669.7 0.749693 0.827048 0.834673 0\n",
      "720 56034.7 0.745478 0.825055 0.832667 0\n",
      "740 55411.7 0.741321 0.823171 0.830775 0\n",
      "760 54799.8 0.737216 0.821384 0.828993 0\n",
      "780 54198.3 0.733158 0.81969 0.827312 0\n",
      "800 53607.5 0.72915 0.818088 0.825733 0\n",
      "820 53027.0 0.725189 0.816581 0.824243 0\n",
      "840 52456.9 0.721279 0.815167 0.822845 0\n",
      "860 51897.5 0.717422 0.813839 0.821534 0\n",
      "880 51348.4 0.713615 0.81258 0.820308 0\n",
      "900 50809.8 0.709862 0.811402 0.819153 0\n",
      "920 50281.7 0.706162 0.810308 0.818069 0\n",
      "940 49764.2 0.702517 0.809288 0.817065 0\n",
      "960 49257.0 0.698927 0.808334 0.816131 0\n",
      "980 48760.2 0.695393 0.807456 0.81526 1\n",
      "1000 48273.6 0.691913 0.806648 0.814455 0\n",
      "1020 47797.9 0.688494 0.805901 0.813712 1\n",
      "1040 47332.0 0.685131 0.805215 0.813027 0\n",
      "1060 46876.4 0.681823 0.804591 0.812395 1\n",
      "1080 46430.8 0.678573 0.80402 0.811817 0\n",
      "1100 45995.0 0.67538 0.803503 0.811294 1\n",
      "1120 45569.1 0.672245 0.803027 0.810824 0\n",
      "1140 45152.6 0.669164 0.802597 0.810396 1\n",
      "1160 44745.3 0.666139 0.80221 0.810012 2\n",
      "1180 44346.6 0.663164 0.801858 0.809666 0\n",
      "1200 43956.7 0.66024 0.801544 0.809356 1\n",
      "1220 43575.6 0.657371 0.801268 0.809079 2\n",
      "1240 43202.8 0.654552 0.801026 0.808836 3\n",
      "1260 42838.3 0.651783 0.800815 0.808627 0\n",
      "1280 42482.1 0.649068 0.80064 0.808447 1\n",
      "1300 42133.8 0.646399 0.800499 0.808301 2\n",
      "1320 41793.6 0.643784 0.800388 0.808189 3\n",
      "1340 41461.6 0.641221 0.8003 0.808111 4\n",
      "1360 41137.2 0.638706 0.800241 0.808056 5\n",
      "1380 40820.1 0.63624 0.800207 0.80803 6\n",
      "1400 40510.5 0.63382 0.800194 0.808024 7\n",
      "1420 40208.3 0.631452 0.800202 0.808039 8\n",
      "1440 39913.3 0.629129 0.800229 0.808079 9\n",
      "1460 39625.3 0.626854 0.800277 0.808142 10\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "minVR = 999\n",
    "not_change_n = 0\n",
    "for i in range(10001):\n",
    "    _, c, r, tr, vr = sess.run([training_step, cost, rmse, test_rmse, valid_rmse])\n",
    "    sess.run(clip)\n",
    "    if i%20 == 0:\n",
    "        print(i, c, r, vr, tr, not_change_n)\n",
    "    \n",
    "        if vr + 0.001 < minVR:\n",
    "            minVR = vr\n",
    "            not_change_n = 0\n",
    "        else:\n",
    "            not_change_n += 1\n",
    "\n",
    "        if not_change_n > 10:\n",
    "            break\n",
    "            \n",
    "    \n",
    "    \"\"\"\n",
    "    if i%500 == 0:\n",
    "        r, tr = sess.run([rmse, test_rmse])\n",
    "        #r = sess.run([rmse])\n",
    "        print(\"rmse:\", i, r, tr)\n",
    "    \"\"\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46849\n",
      "0.591013\n",
      "0.593347\n"
     ]
    }
   ],
   "source": [
    "train_mae = tf.reduce_mean(tf.abs(tf.subtract(rates_train, R_test)))\n",
    "test_mae = tf.reduce_mean(tf.abs(tf.subtract(rates_test, test_R_test)))\n",
    "valid_mae = tf.reduce_mean(tf.abs(tf.subtract(rates_valid, valid_R_test)))\n",
    "mae_tr, mae_v, mae_t = sess.run([train_mae, valid_mae, test_mae])\n",
    "print(mae_tr)\n",
    "print(mae_v)\n",
    "print(mae_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ws3.6",
   "language": "python",
   "name": "ws"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
