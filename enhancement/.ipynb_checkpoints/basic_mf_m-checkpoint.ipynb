{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Global values\n",
    "\"\"\"\n",
    "FEATURE_LEN = 5\n",
    "folder = 'boxoffice_10'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training number:  79460\n",
      "validaton number:  9933\n",
      "test number:  9933\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_rating = pickle.load(open('../data/'+folder+'/user_rating.pkl', 'rb'))\n",
    "\n",
    "user_rating_valid = pickle.load(open('../data/'+folder+'/user_rating_validation.pkl', 'rb'))\n",
    "\n",
    "user_rating_test = pickle.load(open('../data/'+folder+'/user_rating_test.pkl', 'rb'))\n",
    "\n",
    "df_train = []\n",
    "max_user = 0\n",
    "max_movie = 0\n",
    "for user in user_rating:\n",
    "    user_i = int(user)\n",
    "    for tup in user_rating[user]:\n",
    "        rating_i = float(tup[1])\n",
    "        movie_i = int(tup[0])\n",
    "        #user_list.append(user_i)\n",
    "        #movie_list.append(movie_i)\n",
    "        #rating_list.append(float(rating_i))\n",
    "        df_train.append([user_i, movie_i, float(rating_i)])\n",
    "        if movie_i > max_movie:\n",
    "            max_movie = movie_i\n",
    "    \n",
    "    if user_i > max_user:\n",
    "        max_user = user_i\n",
    "        \n",
    "df_test = []\n",
    "for user in user_rating_test:\n",
    "    user_i = int(user)\n",
    "    for tup in user_rating_test[user]:\n",
    "        rating_i = float(tup[1])\n",
    "        movie_i = int(tup[0])\n",
    "        #user_list.append(user_i)\n",
    "        #movie_list.append(movie_i)\n",
    "        #rating_list.append(float(rating_i))\n",
    "        df_test.append([user_i, movie_i, float(rating_i)])\n",
    "        if movie_i > max_movie:\n",
    "            max_movie = movie_i\n",
    "    \n",
    "    if user_i > max_user:\n",
    "        max_user = user_i\n",
    "        \n",
    "\n",
    "df_valid = []\n",
    "for user in user_rating_valid:\n",
    "    user_i = int(user)\n",
    "    for tup in user_rating_valid[user]:\n",
    "        rating_i = float(tup[1])\n",
    "        movie_i = int(tup[0])\n",
    "        #user_list.append(user_i)\n",
    "        #movie_list.append(movie_i)\n",
    "        #rating_list.append(float(rating_i))\n",
    "        df_valid.append([user_i, movie_i, float(rating_i)])\n",
    "        if movie_i > max_movie:\n",
    "            max_movie = movie_i\n",
    "    \n",
    "    if user_i > max_user:\n",
    "        max_user = user_i\n",
    "\n",
    "#user_s, movie_s, rating_s = shuffle(user_list, movie_list, rating_list)\n",
    "\n",
    "#df_train, df_test = train_test_split(df, test_size = 0.2)\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "user_s = [t[0] for t in df_train]\n",
    "movie_s = [t[1] for t in df_train]\n",
    "rating_s = [t[2] for t in df_train]\n",
    "\n",
    "user_s_test = [t[0] for t in df_test]\n",
    "movie_s_test = [t[1] for t in df_test]\n",
    "rating_s_test = [t[2] for t in df_test]\n",
    "\n",
    "user_s_valid = [t[0] for t in df_valid]\n",
    "movie_s_valid = [t[1] for t in df_valid]\n",
    "rating_s_valid = [t[2] for t in df_valid]\n",
    "\n",
    "print(\"training number: \", len(user_s))\n",
    "print(\"validaton number: \", len(user_s_valid))\n",
    "print(\"test number: \", len(user_s_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_indecies_train = user_s\n",
    "item_indecies_train = movie_s\n",
    "rates_train = rating_s\n",
    "\n",
    "user_indecies_test = user_s_test\n",
    "item_indecies_test = movie_s_test\n",
    "rates_test = rating_s_test\n",
    "\n",
    "user_indecies_valid = user_s_valid\n",
    "item_indecies_valid = movie_s_valid\n",
    "rates_valid = rating_s_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79460"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totle_len = len(user_s)\n",
    "totle_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max user: 3549\n",
      "max movie: 206\n",
      "[2.0, 3.0, 4.0, 4.0, 3.5, 4.0, 3.0, 3.5, 2.0, 3.5]\n",
      "3550 207\n"
     ]
    }
   ],
   "source": [
    "def get_bias(user, movie, rating):\n",
    "    print('max user:', max_user)\n",
    "    print('max movie:', max_movie)\n",
    "    average = np.mean(rating)\n",
    "    user_dict = {}\n",
    "    movie_dict = {}\n",
    "    for i in range(len(user)):\n",
    "        user_dict[user[i]] = [rating[i]] if user[i] not in user_dict else user_dict[user[i]] + [rating[i]]\n",
    "        movie_dict[movie[i]] = [rating[i]] if movie[i] not in movie_dict else movie_dict[movie[i]] + [rating[i]]\n",
    "    \n",
    "    user_bias = [0 for i in range(max_user + 1)]\n",
    "    movie_bias = [0 for i in range(max_movie + 1)]\n",
    "    print(user_dict[2253])\n",
    "    print(len(user_bias), len(movie_bias))\n",
    "    for key in user_dict:\n",
    "        user_bias[int(key)] = np.mean(user_dict[key]) - average\n",
    "    for key in movie_dict:\n",
    "        movie_bias[int(key)] = np.mean(movie_dict[key]) - average\n",
    "    \n",
    "    return user_bias, movie_bias, average\n",
    "\n",
    "user_bias, movie_bias, average_score = get_bias(user_s, movie_s, rating_s)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_bias_r = np.reshape(user_bias,[-1,1])\n",
    "movie_bias_r = np.reshape(movie_bias,[1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "U = tf.Variable(initial_value=tf.truncated_normal([max_user+1, FEATURE_LEN], stddev=0.2, mean=0), name='users')\n",
    "P = tf.Variable(initial_value=tf.truncated_normal([FEATURE_LEN, max_movie+1], stddev=0.2, mean=0), name='movies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "U_plus_bias = tf.concat([U, tf.constant(user_bias_r, dtype=tf.float32, name=\"user_bias\"), tf.ones((max_user+1,1), dtype=tf.float32, name=\"user_bias_ones\")], 1)\n",
    "P_plus_bias = tf.concat([P, tf.ones((1, max_movie+1), name=\"movie_bias_ones\", dtype=tf.float32), tf.constant(movie_bias_r, dtype=tf.float32, name=\"movie_bias\")], 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#result = tf.matmul(U_plus_bias, P_plus_bias)\n",
    "result = tf.matmul(U, P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_flatten = tf.reshape(result, [-1])\n",
    "R = tf.gather(result_flatten, user_s * tf.shape(result)[1] + movie_s, name='extracting_user_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diff_op = tf.subtract(R, rating_s, name='trainig_diff')\n",
    "diff_op_squared = tf.nn.l2_loss(diff_op, name=\"squared_difference\")\n",
    "base_cost = tf.reduce_sum(diff_op_squared, name=\"sum_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda = tf.constant(0.001, name='lambda')\n",
    "norm_sums = tf.add(tf.reduce_sum(tf.nn.l2_loss(U, name='user_abs'), name='user_norm'), \n",
    "   tf.reduce_sum(tf.nn.l2_loss(P, name='item_abs'), name='item_norm'))\n",
    "regularizer = tf.multiply(norm_sums, lda, 'regularizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.add(base_cost, regularizer)\n",
    "#cost = base_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = tf.constant(.0001, name='learning_rate')\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "learning_rate = tf.train.exponential_decay(lr, global_step, 10000, 0.98, staircase=True)\n",
    "#learning_rate = 0.01\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "training_step = optimizer.minimize(cost, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# accuracy\n",
    "R_test = tf.gather(result_flatten, user_indecies_train * tf.shape(result)[1] + item_indecies_train, name='extracting_user_rate_test')\n",
    "#R_test = tf.cast(R_test, tf.float64)\n",
    "rmse = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(rates_train, R_test))))\n",
    "#print(sess.run(rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in user_indecies_train:\n",
    "    if i < 0:\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# accuracy\n",
    "test_R_test = tf.gather(result_flatten, user_indecies_test * tf.shape(result)[1] + item_indecies_test, name='extracting_user_rate_test')\n",
    "#test_R_test = tf.cast(test_R_test, tf.float64)\n",
    "test_rmse = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(rates_test, test_R_test))))\n",
    "#print(sess.run(rmse))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# accuracy\n",
    "valid_R_test = tf.gather(result_flatten, user_indecies_valid * tf.shape(result)[1] + item_indecies_valid, name='extracting_user_rate_valid')\n",
    "#test_R_test = tf.cast(test_R_test, tf.float64)\n",
    "valid_rmse = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(rates_valid, valid_R_test))))\n",
    "#print(sess.run(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 520588.0 3.61982 3.63116 3.60905 0\n",
      "20 519819.0 3.61715 3.63054 3.60883 0\n",
      "40 517446.0 3.60888 3.62444 3.60385 1\n",
      "60 502868.0 3.55768 3.57732 3.55952 0\n",
      "80 418406.0 3.24519 3.28017 3.26771 0\n",
      "100 215482.0 2.32887 2.39609 2.39233 0\n",
      "120 99033.8 1.57881 1.65928 1.65986 0\n",
      "140 57626.6 1.20433 1.28307 1.28115 0\n",
      "160 40573.9 1.01054 1.08239 1.07923 0\n",
      "180 32538.4 0.904945 0.970057 0.967176 0\n",
      "200 28294.7 0.843866 0.903919 0.90196 0\n",
      "220 25827.2 0.806227 0.862879 0.862014 0\n",
      "240 24271.9 0.781571 0.836074 0.836276 0\n",
      "260 23224.5 0.764519 0.817733 0.818895 0\n",
      "280 22480.5 0.75217 0.80467 0.806659 0\n",
      "300 21929.1 0.742888 0.795052 0.79773 0\n",
      "320 21506.3 0.735691 0.787775 0.791015 0\n",
      "340 21173.1 0.729968 0.782145 0.785835 0\n",
      "360 20904.4 0.725321 0.777708 0.781753 0\n",
      "380 20683.4 0.721476 0.774158 0.778478 0\n",
      "400 20498.5 0.718243 0.771279 0.775809 0\n",
      "420 20341.3 0.715482 0.768917 0.773607 0\n",
      "440 20205.7 0.713093 0.766962 0.771768 0\n",
      "460 20087.0 0.710996 0.765327 0.770217 0\n",
      "480 19981.9 0.709132 0.763949 0.768898 0\n",
      "500 19887.5 0.707455 0.76278 0.767765 0\n",
      "520 19801.7 0.705927 0.76178 0.766787 0\n",
      "540 19722.9 0.70452 0.760919 0.765935 1\n",
      "560 19649.7 0.703212 0.760175 0.765189 0\n",
      "580 19580.9 0.70198 0.759526 0.764531 1\n",
      "600 19515.7 0.700808 0.758959 0.763948 0\n",
      "620 19453.3 0.699687 0.75846 0.763428 1\n",
      "640 19393.0 0.698602 0.758019 0.762961 0\n",
      "660 19334.4 0.697545 0.757628 0.76254 1\n",
      "680 19277.0 0.696509 0.75728 0.762158 2\n",
      "700 19220.4 0.695485 0.756968 0.76181 0\n",
      "720 19164.3 0.694471 0.756688 0.76149 1\n",
      "740 19108.6 0.693458 0.756437 0.761195 2\n",
      "760 19052.8 0.692446 0.75621 0.760922 3\n",
      "780 18996.9 0.691429 0.756005 0.760668 0\n",
      "800 18940.7 0.690405 0.755821 0.76043 1\n",
      "820 18884.0 0.689371 0.755654 0.760206 2\n",
      "840 18826.8 0.688326 0.755503 0.759994 3\n",
      "860 18769.0 0.687268 0.755367 0.759794 4\n",
      "880 18710.4 0.686194 0.755245 0.759604 5\n",
      "900 18651.1 0.685106 0.755137 0.759422 6\n",
      "920 18591.1 0.684002 0.755041 0.759249 0\n",
      "940 18530.2 0.68288 0.754958 0.759083 1\n",
      "960 18468.5 0.681744 0.754886 0.758924 2\n",
      "980 18406.1 0.68059 0.754826 0.758772 3\n",
      "1000 18342.9 0.679421 0.754778 0.758627 4\n",
      "1020 18279.0 0.678235 0.754741 0.758488 5\n",
      "1040 18214.4 0.677037 0.754716 0.758356 6\n",
      "1060 18149.2 0.675823 0.754703 0.758231 7\n",
      "1080 18083.5 0.674597 0.754701 0.758112 8\n",
      "1100 18017.2 0.67336 0.754711 0.758 9\n",
      "1120 17950.5 0.672111 0.754734 0.757895 10\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "minVR = 999\n",
    "not_change_n = 0\n",
    "for i in range(10001):\n",
    "    _, c, r, tr, vr = sess.run([training_step, cost, rmse, test_rmse, valid_rmse])\n",
    "    if i%20 == 0:\n",
    "        print(i, c, r, vr, tr, not_change_n)\n",
    "    \n",
    "        if vr + 0.001 < minVR:\n",
    "            minVR = vr\n",
    "            not_change_n = 0\n",
    "        else:\n",
    "            not_change_n += 1\n",
    "\n",
    "        if not_change_n > 10:\n",
    "            break\n",
    "            \n",
    "    \n",
    "    \"\"\"\n",
    "    if i%500 == 0:\n",
    "        r, tr = sess.run([rmse, test_rmse])\n",
    "        #r = sess.run([rmse])\n",
    "        print(\"rmse:\", i, r, tr)\n",
    "    \"\"\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.509983\n",
      "0.562836\n",
      "0.562382\n"
     ]
    }
   ],
   "source": [
    "train_mae = tf.reduce_mean(tf.abs(tf.subtract(rates_train, R_test)))\n",
    "test_mae = tf.reduce_mean(tf.abs(tf.subtract(rates_test, test_R_test)))\n",
    "valid_mae = tf.reduce_mean(tf.abs(tf.subtract(rates_valid, valid_R_test)))\n",
    "mae_tr, mae_v, mae_t = sess.run([train_mae, valid_mae, test_mae])\n",
    "print(mae_tr)\n",
    "print(mae_v)\n",
    "print(mae_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_rating = pickle.load(open('../data/'+folder+'/movie_rating.pkl', 'rb'))\n",
    "movie_rating_test = pickle.load(open('../data/'+folder+'/movie_rating_test.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_U, _P, _result = sess.run([U,P, result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "_p = np.transpose(_P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_not_in = 0\n",
    "vv_predict = []\n",
    "vv_y = []\n",
    "largest_num = 10\n",
    "_RMSE_list = []\n",
    "for largest_num in range(0,200, 3): \n",
    "    for m in range(0, max_movie+1):\n",
    "        if (m not in movie_rating or len(movie_rating[m]) <=largest_num) and m in movie_rating_test:\n",
    "            #print('not in', m)\n",
    "            #print(movie_rating_test[m])\n",
    "            for pair in movie_rating_test[m]:\n",
    "                movie_n = m\n",
    "                user_n = pair[0]\n",
    "                vv_predict.append(np.dot(_U[user_n], _p[movie_n]))\n",
    "                vv_y.append(pair[1])\n",
    "            total_not_in += len(movie_rating_test[m])\n",
    "\n",
    "    _RMSE = np.sqrt(np.mean(np.square(np.subtract(vv_predict, vv_y))))\n",
    "    _RMSE_list.append((largest_num, _RMSE))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23916"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_not_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87254525898786883"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.mean(np.square(np.subtract(vv_predict, vv_y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5462895, 2.3699255, 0.13712353, 1.2692664)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_P[0][0], _P[1][0], _P[2][0], _P[3][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5462895 ,  2.3699255 ,  0.13712353,  1.26926637,  3.43433809], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 3.6258421391248703),\n",
       " (3, 3.6258421391248703),\n",
       " (6, 3.6258421391248703),\n",
       " (9, 3.6258421391248703),\n",
       " (12, 2.837444897442265),\n",
       " (15, 2.2519095233334738),\n",
       " (18, 1.9121345867875235),\n",
       " (21, 1.7210454130907764),\n",
       " (24, 1.6342752068025699),\n",
       " (27, 1.5491208984295477),\n",
       " (30, 1.4996049141793095),\n",
       " (33, 1.4373366665012484),\n",
       " (36, 1.397284022479953),\n",
       " (39, 1.3553378108986547),\n",
       " (42, 1.3159823619784152),\n",
       " (45, 1.274130739578633),\n",
       " (48, 1.2373215420332804),\n",
       " (51, 1.2071686395590406),\n",
       " (54, 1.1816532839965599),\n",
       " (57, 1.1613372698676541),\n",
       " (60, 1.1381251018165812),\n",
       " (63, 1.1164263998988779),\n",
       " (66, 1.0973094125560732),\n",
       " (69, 1.0821967295889003),\n",
       " (72, 1.066129484465514),\n",
       " (75, 1.0530420868020742),\n",
       " (78, 1.0401000740227173),\n",
       " (81, 1.0292645663987006),\n",
       " (84, 1.0200585527554462),\n",
       " (87, 1.0098344220242743),\n",
       " (90, 0.99950079848241913),\n",
       " (93, 0.99013542820377343),\n",
       " (96, 0.9808000103727077),\n",
       " (99, 0.9711535789934862),\n",
       " (102, 0.96234766582268816),\n",
       " (105, 0.95372487409674134),\n",
       " (108, 0.94543392138399063),\n",
       " (111, 0.93791018202282195),\n",
       " (114, 0.93101079978091361),\n",
       " (117, 0.92476027475226374),\n",
       " (120, 0.91930584226690715),\n",
       " (123, 0.91450427862464623),\n",
       " (126, 0.91024481860515882),\n",
       " (129, 0.90644044290785597),\n",
       " (132, 0.90358439939562196),\n",
       " (135, 0.90142984734381892),\n",
       " (138, 0.89946008159340629),\n",
       " (141, 0.89754896745457724),\n",
       " (144, 0.89582903631094601),\n",
       " (147, 0.89427295834361098),\n",
       " (150, 0.89285837725004025),\n",
       " (153, 0.89156682785494656),\n",
       " (156, 0.89007900638093662),\n",
       " (159, 0.88871969410130724),\n",
       " (162, 0.88747292630661345),\n",
       " (165, 0.88631723161392617),\n",
       " (168, 0.88487130398390623),\n",
       " (171, 0.88353912409680313),\n",
       " (174, 0.88177386711843042),\n",
       " (177, 0.88009180554414701),\n",
       " (180, 0.87853607909769327),\n",
       " (183, 0.87709296334838038),\n",
       " (186, 0.87608575134181632),\n",
       " (189, 0.87515009852478287),\n",
       " (192, 0.87427863898601399),\n",
       " (195, 0.87338168523416992),\n",
       " (198, 0.87254525898786883)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_RMSE_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('MF_RMSE.csv','w') as f:\n",
    "    f_csv = csv.writer(f)\n",
    "    headers = ['num, RMSE']\n",
    "    f_csv.writerow(headers)\n",
    "    for p in _RMSE_list:\n",
    "        row = [p[0], p[1]]\n",
    "        f_csv.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ws3.6",
   "language": "python",
   "name": "ws"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
