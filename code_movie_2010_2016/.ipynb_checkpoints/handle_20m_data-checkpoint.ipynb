{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "FILE_NAME = 'year2010_movie'\n",
    "RATING_FILE = 'movie_year_2011_2016.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "  return 1 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load movie info matrix\n",
    "index = 0\n",
    "title_dict = {}\n",
    "rating_dict = {}\n",
    "director_dict = {}\n",
    "cast_dict = {}\n",
    "country_dict = {}\n",
    "genre_dict = {}\n",
    "year_dict = {}\n",
    "lmid_2_id = {}\n",
    "infor_dict = {}\n",
    "with open('../data/'+FILE_NAME+'/movie_info.csv',encoding = \"ISO-8859-1\") as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headers = next(f_csv)\n",
    "    for row in f_csv:\n",
    "        infor_dict[row[0]] = row    #### row[0] is the given id in movie_info.csv\n",
    "\n",
    "\n",
    "# every dictionary's id is the given movie id\n",
    "for key in infor_dict:\n",
    "    row = infor_dict[key]\n",
    "    title_dict[key] = [row[4]]\n",
    "    rating_dict[key] = [row[5]]\n",
    "    director_dict[key] = row[6].split('<sp>')\n",
    "    cast_dict[key] = row[7].split('<sp>')\n",
    "    country_dict[key] = row[8].split('<sp>')\n",
    "    genre_dict[key] = row[9].split('<sp>')\n",
    "    year_dict[key] = [row[10]]\n",
    "    # key: id in movielens 1m, value: id in id we use\n",
    "    lmid_2_id[row[1]] = row[0]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 规定，所有的user id为后面定义的user id， movie id用movie_info.csv里面的id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(lmid_2_id, open('../data/'+FILE_NAME+'/lmid_2_id.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len_dtcgum = [0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "director_2_id = {}\n",
    "id_2_director = {}\n",
    "i = 0\n",
    "for key in director_dict:\n",
    "    for name in director_dict[key]:\n",
    "        if name not in director_2_id:\n",
    "            director_2_id[name] = i\n",
    "            id_2_director[i] = name\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3715"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_director = 0\n",
    "for key in id_2_director:\n",
    "    if max_director < int(key):\n",
    "        max_director = int(key)\n",
    "len_dtcgum[0] = max_director + 1\n",
    "max_director + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# only calculate the first three casts\n",
    "cast_2_id = {}\n",
    "id_2_cast = {}\n",
    "i = 0\n",
    "for key in cast_dict:\n",
    "    for name in cast_dict[key][0:2]:\n",
    "        if name not in cast_2_id:\n",
    "            cast_2_id[name] = i\n",
    "            id_2_cast[i] = name\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5566"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_cast = 0\n",
    "for key in id_2_cast:\n",
    "    if max_cast < int(key):\n",
    "        max_cast = int(key)\n",
    "len_dtcgum[2] = max_cast + 1\n",
    "max_cast + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genre_2_id = {}\n",
    "id_2_genre = {}\n",
    "i = 0\n",
    "for key in genre_dict:\n",
    "    for name in genre_dict[key]:\n",
    "        if name not in genre_2_id:\n",
    "            genre_2_id[name] = i\n",
    "            id_2_genre[i] = name\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_genre = 0\n",
    "for key in id_2_genre:\n",
    "    if max_genre < int(key):\n",
    "        max_genre = int(key)\n",
    "len_dtcgum[3] = max_genre + 1\n",
    "max_genre + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#handle user id\n",
    "mid_2_realid = {}\n",
    "max_movie_id = 0\n",
    "for line in open('../data/rating_time/' + RATING_FILE, 'r'):\n",
    "    #item = line.rstrip().split(\"::\")\n",
    "    item_info = line.rstrip().split(\",\")\n",
    "    if item_info[0] != 'userid':\n",
    "        max_movie_id = int(lmid_2_id[item_info[1]]) if int(lmid_2_id[item_info[1]]) > max_movie_id else max_movie_id\n",
    "        if item_info[0] not in mid_2_realid:\n",
    "            mid_2_realid[item_info[0]] = len(mid_2_realid)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3906"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_movie_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 0\n",
    "for line in open('../data/rating_time/' + RATING_FILE, 'r'):\n",
    "    item_info = line.rstrip().split(\",\")\n",
    "    if item_info[0]  == '138419':\n",
    "        index += 1\n",
    "            \n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len_dtcgum[4] = len(mid_2_realid)\n",
    "len_dtcgum[5] = max_movie_id\n",
    "\n",
    "pickle.dump(len_dtcgum, open('../data/'+FILE_NAME+'/len_dtcgum.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = 0\n",
    "movie_rating = {}\n",
    "train_temp = []\n",
    "test_temp = []\n",
    "for line in open('../data/rating_time/'+RATING_FILE, 'r'):\n",
    "    #item = line.rstrip().split(\"::\")\n",
    "    item_info = line.rstrip().split(\",\")\n",
    "    if item_info[0] != 'userid':\n",
    "        item_info[0] = mid_2_realid[item_info[0]]\n",
    "        item_info[1] = lmid_2_id[item_info[1]]\n",
    "        train_temp.append(item_info)\n",
    "    \n",
    "\n",
    "data_tmp = train_temp\n",
    "train, test_validation = train_test_split(data_tmp, test_size = 0.2)\n",
    "test, validation = train_test_split(test_validation, test_size = 0.5)\n",
    "#train, validation = train_test_split(train_temp, test_size = 0.25)\n",
    "#test = test_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def change_to_int(data):\n",
    "    result = []\n",
    "    for info in data:\n",
    "        one_info = []\n",
    "        for n in info[0:-2]:\n",
    "            one_info.append(int(n))\n",
    "        one_info.append(float(info[-2]))    \n",
    "        \n",
    "        result.append(one_info)\n",
    "    return result\n",
    "\n",
    "train_all = change_to_int(train)\n",
    "test_all = change_to_int(test)\n",
    "validation_all = change_to_int(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(train_all, open('../data/'+FILE_NAME+'/train_all.pkl', 'wb'))\n",
    "pickle.dump(test_all, open('../data/'+FILE_NAME+'/test_all.pkl', 'wb'))\n",
    "pickle.dump(validation_all, open('../data/'+FILE_NAME+'/validation_all.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_rating_data(df):\n",
    "    user_rating = {}\n",
    "    movie_rating = {}\n",
    "    index = 0\n",
    "    for item in df:\n",
    "        try:\n",
    "            #real_id is the 1m id\n",
    "            user_id = item[0]\n",
    "            movie_id = int(item[1])\n",
    "            rating = float(item[2])\n",
    "            user_rating[user_id] = [(movie_id, rating)] if user_id not in user_rating else (user_rating[user_id] + [(movie_id, rating)])\n",
    "            movie_rating[movie_id] = [(user_id, rating)] if movie_id not in movie_rating else (movie_rating[movie_id] + [(user_id, rating)])\n",
    "        except:\n",
    "            index += 1\n",
    "            pass\n",
    "    \n",
    "    print(index)\n",
    "    return user_rating, movie_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "user_rating, movie_rating = gen_rating_data(train)\n",
    "user_rating_test, movie_rating_test = gen_rating_data(test)\n",
    "user_rating_validation, movie_rating_validation = gen_rating_data(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data for training, the exact movie rating for each user\n",
    "train_user = [int(inf[0]) for inf in train]\n",
    "train_movie = [int(inf[1]) for inf in train]\n",
    "train_rating = [float(inf[2]) for inf in train]\n",
    "\n",
    "pickle.dump(train_user, open('../data/'+FILE_NAME+'/train_user.pkl', 'wb'))\n",
    "pickle.dump(train_movie, open('../data/'+FILE_NAME+'/train_movie.pkl', 'wb'))\n",
    "pickle.dump(train_rating, open('../data/'+FILE_NAME+'/train_rating.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data for training, the exact movie rating for each user\n",
    "valid_user = [int(inf[0]) for inf in validation]\n",
    "valid_movie = [int(inf[1]) for inf in validation]\n",
    "valid_rating = [float(inf[2]) for inf in validation]\n",
    "\n",
    "pickle.dump(valid_user, open('../data/'+FILE_NAME+'/valid_user.pkl', 'wb'))\n",
    "pickle.dump(valid_movie, open('../data/'+FILE_NAME+'/valid_movie.pkl', 'wb'))\n",
    "pickle.dump(valid_rating, open('../data/'+FILE_NAME+'/valid_rating.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data for testing, the exact movie rating for each user\n",
    "test_user = [int(inf[0]) for inf in test]\n",
    "test_movie = [int(inf[1]) for inf in test]\n",
    "test_rating = [float(inf[2]) for inf in test]\n",
    "\n",
    "pickle.dump(test_user, open('../data/'+FILE_NAME+'/test_user.pkl', 'wb'))\n",
    "pickle.dump(test_movie, open('../data/'+FILE_NAME+'/test_movie.pkl', 'wb'))\n",
    "pickle.dump(test_rating, open('../data/'+FILE_NAME+'/test_rating.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(user_rating, open('../data/'+FILE_NAME+'/user_rating.pkl', 'wb'))\n",
    "pickle.dump(movie_rating, open('../data/'+FILE_NAME+'/movie_rating.pkl', 'wb'))\n",
    "pickle.dump(user_rating_test, open('../data/'+FILE_NAME+'/user_rating_test.pkl', 'wb'))\n",
    "pickle.dump(movie_rating_test, open('../data/'+FILE_NAME+'/movie_rating_test.pkl', 'wb'))\n",
    "pickle.dump(user_rating_validation, open('../data/'+FILE_NAME+'/user_rating_validation.pkl', 'wb'))\n",
    "pickle.dump(movie_rating_validation, open('../data/'+FILE_NAME+'/movie_rating_validation.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_of_1 = 0\n",
    "def core_fn(scores):\n",
    "    global num_of_1\n",
    "    \"\"\"\n",
    "    core function that wrap the score according to how \n",
    "    many number of scores contribute the score \n",
    "    Currently: the average score\n",
    "    \"\"\"\n",
    "    # scores is the list of (proportion, rating)\n",
    "    sum_p = 0.\n",
    "    sum_r = 0.\n",
    "    num = len(scores) - 1\n",
    "    for tup in scores:\n",
    "        prop = float(tup[0]) \n",
    "        r = float(tup[1])\n",
    "        sum_r += prop * r\n",
    "        #sum_r += r\n",
    "        sum_p += prop\n",
    "    \n",
    "    if num == 1:\n",
    "        num_of_1 += 1\n",
    "    #return (sum_r/sum_p) * (0.3 + sigmoid(num+1))\n",
    "    return (sum_r/sum_p), sum_p\n",
    "    #result = sum_r/float(num) if num > 0 else 0\n",
    "    #return result\n",
    "\n",
    "def generate_proportion(info_list, is_cast):\n",
    "    if is_cast:\n",
    "        assert len(info_list) <= 3\n",
    "        if len(info_list) == 3:\n",
    "            return [(info_list[0], 1), (info_list[1], 0.8), (info_list[2], 0.6)]\n",
    "        elif len(info_list) == 2:\n",
    "            return [(info_list[0], 1), (info_list[1], 0.8)]   \n",
    "        elif len(info_list) == 1:\n",
    "            return [(info_list[0], 1)]\n",
    "        else:\n",
    "            return []\n",
    "    else:\n",
    "        result = []\n",
    "        prop = 1./len(info_list) if len(info_list) > 0 else 0\n",
    "        #prop = 1\n",
    "        for _id in info_list:\n",
    "            result.append((_id, prop))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_count_list = {}\n",
    "user_count_list['d'] = {}\n",
    "user_count_list['c'] = {}\n",
    "user_count_list['t'] = {}\n",
    "user_count_list['g'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get special part score\n",
    "def user_info_score(user_key, inputs, to_id_dict, movie_info_dict, dict_name, is_cast=False):\n",
    "    \"\"\"\n",
    "    inputs: list of tuples (movieID, rating) for one user\n",
    "    output: list of tuples (InfoID, rating) for the user\n",
    "    \"\"\"\n",
    "    result_list = []\n",
    "    score_dict = {}\n",
    "    for tup in inputs:\n",
    "        rating = float(tup[1])\n",
    "        info_list = movie_info_dict[str(tup[0])][0:2] if is_cast else movie_info_dict[str(tup[0])]\n",
    "        info_list_prop = generate_proportion(info_list, is_cast)\n",
    "        for one_info in info_list_prop:\n",
    "            # one_info has form (info_id, proportion)\n",
    "            info_id = to_id_dict[one_info[0]]\n",
    "            if info_id not in score_dict:\n",
    "                score_dict[info_id] = [(one_info[1], rating)]\n",
    "            else:\n",
    "                score_dict[info_id].append((one_info[1], rating))\n",
    "    \n",
    "    for info_key in score_dict:\n",
    "        scores, proportion = core_fn(score_dict[info_key])\n",
    "        result_list.append([user_key, info_key, scores])\n",
    "        if user_key not in user_count_list[dict_name]:\n",
    "            user_count_list[dict_name][user_key] = {}\n",
    "\n",
    "        user_count_list[dict_name][user_key][info_key] = proportion\n",
    "    \n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11193\n"
     ]
    }
   ],
   "source": [
    "director_rating = []\n",
    "num_of_1 = 0\n",
    "for key in user_rating:\n",
    "    director_rating += user_info_score(key, user_rating[key], director_2_id, director_dict, 'd')\n",
    "    \n",
    "print(num_of_1)\n",
    "train_user_d = [int(info[0]) for info in director_rating]\n",
    "train_movie_d = [int(info[1]) for info in director_rating]\n",
    "train_rating_d = [float(info[2]) for info in director_rating]\n",
    "\n",
    "pickle.dump(train_user_d, open('../data/'+FILE_NAME+'/train_user_d.pkl', 'wb'))\n",
    "pickle.dump(train_movie_d, open('../data/'+FILE_NAME+'/train_movie_d.pkl', 'wb'))\n",
    "pickle.dump(train_rating_d, open('../data/'+FILE_NAME+'/train_rating_d.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7377\n"
     ]
    }
   ],
   "source": [
    "num_of_1 = 0\n",
    "genre_rating = []\n",
    "for key in user_rating:\n",
    "    genre_rating += user_info_score(key, user_rating[key], genre_2_id, genre_dict, 'g')\n",
    "print(num_of_1)\n",
    "train_user_g = [int(info[0]) for info in genre_rating]\n",
    "train_movie_g = [int(info[1]) for info in genre_rating]\n",
    "train_rating_g = [float(info[2]) for info in genre_rating]\n",
    "\n",
    "pickle.dump(train_user_g, open('../data/'+FILE_NAME+'/train_user_g.pkl', 'wb'))\n",
    "pickle.dump(train_movie_g, open('../data/'+FILE_NAME+'/train_movie_g.pkl', 'wb'))\n",
    "pickle.dump(train_rating_g, open('../data/'+FILE_NAME+'/train_rating_g.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32407\n"
     ]
    }
   ],
   "source": [
    "num_of_1 = 0\n",
    "cast_rating = []\n",
    "for key in user_rating:\n",
    "    cast_rating += user_info_score(key, user_rating[key], cast_2_id, cast_dict,'c', is_cast=True)\n",
    "\n",
    "print(num_of_1)\n",
    "train_user_c = [int(info[0]) for info in cast_rating]\n",
    "train_movie_c = [int(info[1]) for info in cast_rating]\n",
    "train_rating_c = [float(info[2]) for info in cast_rating]\n",
    "\n",
    "pickle.dump(train_user_c, open('../data/'+FILE_NAME+'/train_user_c.pkl', 'wb'))\n",
    "pickle.dump(train_movie_c, open('../data/'+FILE_NAME+'/train_movie_c.pkl', 'wb'))\n",
    "pickle.dump(train_rating_c, open('../data/'+FILE_NAME+'/train_rating_c.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_dict = pickle.load(open('../data/year2010_movie/topic_dict.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def topic_core_fn(scores):\n",
    "    # scores is the list of (proportion, rating)\n",
    "    sum_p = 0.\n",
    "    sum_r = 0.\n",
    "    num = len(scores)\n",
    "    for tup in scores:\n",
    "        prop = float(tup[0]) \n",
    "        r = float(tup[1])\n",
    "        sum_r += prop * r\n",
    "        sum_p += prop\n",
    "    \n",
    "    return sum_r/sum_p * sigmoid(num)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def user_topic_score(user_key, inputs):\n",
    "    \"\"\"\n",
    "    inputs: list of tuples (movieID, rating) for one user\n",
    "    output: list of tuples (castID, rating) for the user\n",
    "    \"\"\"\n",
    "    result_list = []\n",
    "    score_dict = {}\n",
    "    for tup in inputs:\n",
    "        rating = tup[1]\n",
    "        # one_info has the form (type_id, proportion)\n",
    "\n",
    "        for one_info in topic_dict[str(tup[0])]:\n",
    "            type_id = one_info[0]\n",
    "            prop = one_info[1]\n",
    "            if type_id not in score_dict:\n",
    "                score_dict[type_id] = [(prop, rating)]\n",
    "            else:\n",
    "                score_dict[type_id].append((prop, rating))\n",
    "\n",
    "    \n",
    "    for key in score_dict:\n",
    "        scores, proportion = core_fn(score_dict[key])\n",
    "        result_list.append([user_key, key, scores])\n",
    "        if user_key not in user_count_list['t']:\n",
    "            user_count_list['t'][user_key] = {}\n",
    "        user_count_list['t'][user_key][key] = proportion\n",
    "    \n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'561'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-5a62233badf4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtopic_rating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muser_rating\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtopic_rating\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0muser_topic_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_rating\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_user_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtopic_rating\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-d6bee4e5bda6>\u001b[0m in \u001b[0;36muser_topic_score\u001b[0;34m(user_key, inputs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# one_info has the form (type_id, proportion)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mone_info\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtopic_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mtype_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mprop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '561'"
     ]
    }
   ],
   "source": [
    "topic_rating = []\n",
    "for key in user_rating:\n",
    "    topic_rating += user_topic_score(key, user_rating[key])\n",
    "\n",
    "train_user_t = [int(info[0]) for info in topic_rating]\n",
    "train_movie_t = [int(info[1]) for info in topic_rating]\n",
    "train_rating_t = [float(info[2]) for info in topic_rating]\n",
    "\n",
    "pickle.dump(train_user_t, open('../data/'+FILE_NAME+'/train_user_t.pkl', 'wb'))\n",
    "pickle.dump(train_movie_t, open('../data/'+FILE_NAME+'/train_movie_t.pkl', 'wb'))\n",
    "pickle.dump(train_rating_t, open('../data/'+FILE_NAME+'/train_rating_t.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(user_count_list, open('../data/'+FILE_NAME+'/user_count_list.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(id_2_genre, open('../data/'+FILE_NAME+'/id_2_genre.pkl', 'wb'))\n",
    "pickle.dump(id_2_director, open('../data/'+FILE_NAME+'/id_2_director.pkl', 'wb'))\n",
    "pickle.dump(id_2_cast, open('../data/'+FILE_NAME+'/id_2_cast.pkl', 'wb'))\n",
    "\n",
    "pickle.dump(genre_2_id, open('../data/'+FILE_NAME+'/genre_2_id.pkl', 'wb'))\n",
    "pickle.dump(director_2_id, open('../data/'+FILE_NAME+'/director_2_id.pkl', 'wb'))\n",
    "pickle.dump(cast_2_id, open('../data/'+FILE_NAME+'/cast_2_id.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(topic_rating, open('../data/'+FILE_NAME+'/topic_rating.pkl', 'wb'))\n",
    "pickle.dump(director_rating, open('../data/'+FILE_NAME+'/director_rating.pkl', 'wb'))\n",
    "pickle.dump(genre_rating, open('../data/'+FILE_NAME+'/genre_rating.pkl', 'wb'))\n",
    "pickle.dump(cast_rating, open('../data/'+FILE_NAME+'/cast_rating.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate validation rating set\n",
    "director_rating_v = []\n",
    "for key in user_rating_validation:\n",
    "    director_rating_v += user_info_score(key, user_rating_validation[key], director_2_id,  director_dict, 'd')\n",
    "\n",
    "train_user_d_v = [int(info[0]) for info in director_rating_v]\n",
    "train_movie_d_v = [int(info[1]) for info in director_rating_v]\n",
    "train_rating_d_v = [float(info[2]) for info in director_rating_v]\n",
    "    \n",
    "cast_rating_v = []\n",
    "for key in user_rating_validation:\n",
    "    cast_rating_v += user_info_score(key, user_rating_validation[key], cast_2_id, cast_dict, 'c', is_cast=True)\n",
    "    \n",
    "train_user_c_v = [int(info[0]) for info in cast_rating_v]\n",
    "train_movie_c_v = [int(info[1]) for info in cast_rating_v]\n",
    "train_rating_c_v = [float(info[2]) for info in cast_rating_v]\n",
    "\n",
    "\n",
    "genre_rating_v = []\n",
    "for key in user_rating_validation:\n",
    "    genre_rating_v += user_info_score(key, user_rating_validation[key], genre_2_id, genre_dict, 'g')  \n",
    "\n",
    "train_user_g_v = [int(info[0]) for info in genre_rating_v]\n",
    "train_movie_g_v = [int(info[1]) for info in genre_rating_v]\n",
    "train_rating_g_v = [float(info[2]) for info in genre_rating_v]\n",
    "    \n",
    "topic_rating_v = []\n",
    "for key in user_rating_validation:\n",
    "    topic_rating_v += user_topic_score(key, user_rating_validation[key])\n",
    "\n",
    "train_user_t_v = [int(info[0]) for info in topic_rating_v]\n",
    "train_movie_t_v = [int(info[1]) for info in topic_rating_v]\n",
    "train_rating_t_v = [float(info[2]) for info in topic_rating_v]    \n",
    "\n",
    "pickle.dump(train_user_d_v, open('../data/'+FILE_NAME+'/train_user_d_v.pkl', 'wb'))\n",
    "pickle.dump(train_movie_d_v, open('../data/'+FILE_NAME+'/train_movie_d_v.pkl', 'wb'))\n",
    "pickle.dump(train_rating_d_v, open('../data/'+FILE_NAME+'/train_rating_d_v.pkl', 'wb'))\n",
    "\n",
    "pickle.dump(train_user_g_v, open('../data/'+FILE_NAME+'/train_user_g_v.pkl', 'wb'))\n",
    "pickle.dump(train_movie_g_v, open('../data/'+FILE_NAME+'/train_movie_g_v.pkl', 'wb'))\n",
    "pickle.dump(train_rating_g_v, open('../data/'+FILE_NAME+'/train_rating_g_v.pkl', 'wb'))\n",
    "\n",
    "pickle.dump(train_user_c_v, open('../data/'+FILE_NAME+'/train_user_c_v.pkl', 'wb'))\n",
    "pickle.dump(train_movie_c_v, open('../data/'+FILE_NAME+'/train_movie_c_v.pkl', 'wb'))\n",
    "pickle.dump(train_rating_c_v, open('../data/'+FILE_NAME+'/train_rating_c_v.pkl', 'wb'))\n",
    "\n",
    "pickle.dump(train_user_t_v, open('../data/'+FILE_NAME+'/train_user_t_v.pkl', 'wb'))\n",
    "pickle.dump(train_movie_t_v, open('../data/'+FILE_NAME+'/train_movie_t_v.pkl', 'wb'))\n",
    "pickle.dump(train_rating_t_v, open('../data/'+FILE_NAME+'/train_rating_t_v.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(topic_rating_v, open('../data/'+FILE_NAME+'/topic_rating_v.pkl', 'wb'))\n",
    "pickle.dump(director_rating_v, open('../data/'+FILE_NAME+'/director_rating_v.pkl', 'wb'))\n",
    "pickle.dump(genre_rating_v, open('../data/'+FILE_NAME+'/genre_rating_v.pkl', 'wb'))\n",
    "pickle.dump(cast_rating_v, open('../data/'+FILE_NAME+'/cast_rating_v.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate movie feature dict\n",
    "#form as movieID: dict with key (director, type, genre, topic)\n",
    "movie_feature_dict = {}\n",
    "\n",
    "movie_id_set = set()\n",
    "for key in movie_rating:\n",
    "    movie_id_set.add(key)\n",
    "for key in movie_rating_validation:\n",
    "    movie_id_set.add(key)\n",
    "\n",
    "for m_id in movie_id_set:\n",
    "    try:\n",
    "        topic_list = [tup[0] for tup in topic_dict[str(m_id)]]\n",
    "    except:\n",
    "        topic_list = []\n",
    "\n",
    "    director_list = [director_2_id[_id] for _id in director_dict[str(m_id)]]\n",
    "\n",
    "    \n",
    "    try:\n",
    "        cast_list = [cast_2_id[_id] for _id in cast_dict[str(m_id)][0:2]]\n",
    "    except:\n",
    "        cast_list = []\n",
    "    try:\n",
    "        genre_list = [genre_2_id[_id] for _id in genre_dict[str(m_id)]]\n",
    "    except:\n",
    "        genre_list = []\n",
    "    tmp_dict = {}\n",
    "    tmp_dict['d'] = director_list\n",
    "    tmp_dict['t'] = topic_list\n",
    "    tmp_dict['g'] = genre_list\n",
    "    tmp_dict['c'] = cast_list\n",
    "    \n",
    "    movie_feature_dict[m_id] = tmp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(movie_feature_dict, open('../data/'+FILE_NAME+'/movie_feature_dict.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ws3.6",
   "language": "python",
   "name": "ws"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
