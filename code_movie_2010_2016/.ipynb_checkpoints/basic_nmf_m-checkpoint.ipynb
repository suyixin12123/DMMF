{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Global values\n",
    "\"\"\"\n",
    "FEATURE_LEN = 5\n",
    "folder = 'year2010_movie'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training number:  201623\n",
      "validaton number:  25203\n",
      "test number:  25203\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_rating = pickle.load(open('../data/'+folder+'/user_rating.pkl', 'rb'))\n",
    "\n",
    "user_rating_valid = pickle.load(open('../data/'+folder+'/user_rating_validation.pkl', 'rb'))\n",
    "\n",
    "user_rating_test = pickle.load(open('../data/'+folder+'/user_rating_test.pkl', 'rb'))\n",
    "\n",
    "df_train = []\n",
    "max_user = 0\n",
    "max_movie = 0\n",
    "for user in user_rating:\n",
    "    user_i = int(user)\n",
    "    for tup in user_rating[user]:\n",
    "        rating_i = float(tup[1])\n",
    "        movie_i = int(tup[0])\n",
    "        #user_list.append(user_i)\n",
    "        #movie_list.append(movie_i)\n",
    "        #rating_list.append(float(rating_i))\n",
    "        df_train.append([user_i, movie_i, float(rating_i)])\n",
    "        if movie_i > max_movie:\n",
    "            max_movie = movie_i\n",
    "    \n",
    "    if user_i > max_user:\n",
    "        max_user = user_i\n",
    "        \n",
    "df_test = []\n",
    "for user in user_rating_test:\n",
    "    user_i = int(user)\n",
    "    for tup in user_rating_test[user]:\n",
    "        rating_i = float(tup[1])\n",
    "        movie_i = int(tup[0])\n",
    "        #user_list.append(user_i)\n",
    "        #movie_list.append(movie_i)\n",
    "        #rating_list.append(float(rating_i))\n",
    "        df_test.append([user_i, movie_i, float(rating_i)])\n",
    "        if movie_i > max_movie:\n",
    "            max_movie = movie_i\n",
    "    \n",
    "    if user_i > max_user:\n",
    "        max_user = user_i\n",
    "        \n",
    "\n",
    "df_valid = []\n",
    "for user in user_rating_valid:\n",
    "    user_i = int(user)\n",
    "    for tup in user_rating_valid[user]:\n",
    "        rating_i = float(tup[1])\n",
    "        movie_i = int(tup[0])\n",
    "        #user_list.append(user_i)\n",
    "        #movie_list.append(movie_i)\n",
    "        #rating_list.append(float(rating_i))\n",
    "        df_valid.append([user_i, movie_i, float(rating_i)])\n",
    "        if movie_i > max_movie:\n",
    "            max_movie = movie_i\n",
    "    \n",
    "    if user_i > max_user:\n",
    "        max_user = user_i\n",
    "\n",
    "#user_s, movie_s, rating_s = shuffle(user_list, movie_list, rating_list)\n",
    "\n",
    "#df_train, df_test = train_test_split(df, test_size = 0.2)\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "user_s = [t[0] for t in df_train]\n",
    "movie_s = [t[1] for t in df_train]\n",
    "rating_s = [t[2] for t in df_train]\n",
    "\n",
    "user_s_test = [t[0] for t in df_test]\n",
    "movie_s_test = [t[1] for t in df_test]\n",
    "rating_s_test = [t[2] for t in df_test]\n",
    "\n",
    "user_s_valid = [t[0] for t in df_valid]\n",
    "movie_s_valid = [t[1] for t in df_valid]\n",
    "rating_s_valid = [t[2] for t in df_valid]\n",
    "\n",
    "print(\"training number: \", len(user_s))\n",
    "print(\"validaton number: \", len(user_s_valid))\n",
    "print(\"test number: \", len(user_s_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_indecies_train = user_s\n",
    "item_indecies_train = movie_s\n",
    "rates_train = rating_s\n",
    "\n",
    "user_indecies_test = user_s_test\n",
    "item_indecies_test = movie_s_test\n",
    "rates_test = rating_s_test\n",
    "\n",
    "user_indecies_valid = user_s_valid\n",
    "item_indecies_valid = movie_s_valid\n",
    "rates_valid = rating_s_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3906"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201623"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totle_len = len(user_s)\n",
    "totle_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max user: 3838\n",
      "max movie: 3906\n",
      "[3.0, 4.0, 4.0, 2.0, 4.5, 4.5, 4.0, 2.0, 4.0, 4.0, 4.0, 4.0, 4.5, 4.0, 3.0, 4.5]\n",
      "3839 3907\n"
     ]
    }
   ],
   "source": [
    "def get_bias(user, movie, rating):\n",
    "    print('max user:', max_user)\n",
    "    print('max movie:', max_movie)\n",
    "    average = np.mean(rating)\n",
    "    user_dict = {}\n",
    "    movie_dict = {}\n",
    "    for i in range(len(user)):\n",
    "        user_dict[user[i]] = [rating[i]] if user[i] not in user_dict else user_dict[user[i]] + [rating[i]]\n",
    "        movie_dict[movie[i]] = [rating[i]] if movie[i] not in movie_dict else movie_dict[movie[i]] + [rating[i]]\n",
    "    \n",
    "    user_bias = [0 for i in range(max_user + 1)]\n",
    "    movie_bias = [0 for i in range(max_movie + 1)]\n",
    "    print(user_dict[2253])\n",
    "    print(len(user_bias), len(movie_bias))\n",
    "    for key in user_dict:\n",
    "        user_bias[int(key)] = np.mean(user_dict[key]) - average\n",
    "    for key in movie_dict:\n",
    "        movie_bias[int(key)] = np.mean(movie_dict[key]) - average\n",
    "    \n",
    "    return user_bias, movie_bias, average\n",
    "\n",
    "user_bias, movie_bias, average_score = get_bias(user_s, movie_s, rating_s)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_bias_r = np.reshape(user_bias,[-1,1])\n",
    "movie_bias_r = np.reshape(movie_bias,[1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "U = tf.Variable(initial_value=tf.truncated_normal([max_user+1, FEATURE_LEN], stddev=0.2, mean=0), name='users')\n",
    "P = tf.Variable(initial_value=tf.truncated_normal([FEATURE_LEN, max_movie+1], stddev=0.2, mean=0), name='movies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "U_plus_bias = tf.concat([U, tf.constant(user_bias_r, dtype=tf.float32, name=\"user_bias\"), tf.ones((max_user+1,1), dtype=tf.float32, name=\"user_bias_ones\")], 1)\n",
    "P_plus_bias = tf.concat([P, tf.ones((1, max_movie+1), name=\"movie_bias_ones\", dtype=tf.float32), tf.constant(movie_bias_r, dtype=tf.float32, name=\"movie_bias\")], 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#result = tf.matmul(U_plus_bias, P_plus_bias)\n",
    "result = tf.matmul(U, P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_flatten = tf.reshape(result, [-1])\n",
    "R = tf.gather(result_flatten, user_s * tf.shape(result)[1] + movie_s, name='extracting_user_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diff_op = tf.subtract(R, rating_s, name='trainig_diff')\n",
    "diff_op_squared = tf.nn.l2_loss(diff_op, name=\"squared_difference\")\n",
    "base_cost = tf.reduce_sum(diff_op_squared, name=\"sum_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda = tf.constant(0.001, name='lambda')\n",
    "norm_sums = tf.add(tf.reduce_sum(tf.nn.l2_loss(U, name='user_abs'), name='user_norm'), \n",
    "   tf.reduce_sum(tf.nn.l2_loss(P, name='item_abs'), name='item_norm'))\n",
    "regularizer = tf.multiply(norm_sums, lda, 'regularizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clip_U = U.assign(tf.maximum(tf.zeros_like(U), U))\n",
    "clip_P = P.assign(tf.maximum(tf.zeros_like(P), P))\n",
    "clip = tf.group(clip_U, clip_P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.add(base_cost, regularizer)\n",
    "#cost = base_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = tf.constant(.0001, name='learning_rate')\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "learning_rate = tf.train.exponential_decay(lr, global_step, 10000, 0.98, staircase=True)\n",
    "#learning_rate = 0.01\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "training_step = optimizer.minimize(cost, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# accuracy\n",
    "R_test = tf.gather(result_flatten, user_indecies_train * tf.shape(result)[1] + item_indecies_train, name='extracting_user_rate_test')\n",
    "#R_test = tf.cast(R_test, tf.float64)\n",
    "rmse = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(rates_train, R_test))))\n",
    "#print(sess.run(rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in user_indecies_train:\n",
    "    if i < 0:\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# accuracy\n",
    "test_R_test = tf.gather(result_flatten, user_indecies_test * tf.shape(result)[1] + item_indecies_test, name='extracting_user_rate_test')\n",
    "#test_R_test = tf.cast(test_R_test, tf.float64)\n",
    "test_rmse = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(rates_test, test_R_test))))\n",
    "#print(sess.run(rmse))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# accuracy\n",
    "valid_R_test = tf.gather(result_flatten, user_indecies_valid * tf.shape(result)[1] + item_indecies_valid, name='extracting_user_rate_valid')\n",
    "#test_R_test = tf.cast(test_R_test, tf.float64)\n",
    "valid_rmse = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(rates_valid, valid_R_test))))\n",
    "#print(sess.run(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.29643e+06 3.58607 3.58844 3.58863 0\n",
      "20 998512.0 3.14718 3.1555 3.15611 0\n",
      "40 446202.0 2.10382 2.12736 2.11806 0\n",
      "60 269297.0 1.63439 1.66216 1.6483 0\n",
      "80 198394.0 1.40283 1.43211 1.41647 0\n",
      "100 162168.0 1.26829 1.29911 1.28199 0\n",
      "120 140543.0 1.1807 1.21319 1.19499 0\n",
      "140 126172.0 1.11871 1.15287 1.13402 0\n",
      "160 115887.0 1.07214 1.1079 1.08877 0\n",
      "180 108130.0 1.03563 1.07288 1.05378 0\n",
      "200 102051.0 1.0061 1.04473 1.02584 0\n",
      "220 97147.3 0.981625 1.02154 1.003 0\n",
      "240 93099.4 0.960953 1.00207 0.983949 0\n",
      "260 89695.7 0.94322 0.985462 0.967787 0\n",
      "280 86789.2 0.927811 0.971112 0.953885 0\n",
      "300 84275.1 0.914271 0.95858 0.941783 0\n",
      "320 82076.4 0.902266 0.947533 0.931141 0\n",
      "340 80135.3 0.89153 0.93772 0.9217 0\n",
      "360 78407.0 0.881862 0.928941 0.913263 0\n",
      "380 76857.2 0.873103 0.921043 0.905671 0\n",
      "400 75458.2 0.865118 0.913899 0.898805 0\n",
      "420 74187.9 0.857804 0.907406 0.892561 0\n",
      "440 73028.1 0.851071 0.901482 0.886859 0\n",
      "460 71964.0 0.844848 0.896057 0.881632 0\n",
      "480 70983.1 0.839069 0.891072 0.876822 0\n",
      "500 70074.9 0.833684 0.886477 0.872383 0\n",
      "520 69230.8 0.828645 0.882229 0.868271 0\n",
      "540 68442.8 0.823914 0.87829 0.86445 0\n",
      "560 67704.2 0.819456 0.874627 0.860891 0\n",
      "580 67009.6 0.81524 0.87121 0.857572 0\n",
      "600 66353.7 0.811241 0.868019 0.854464 0\n",
      "620 65732.2 0.807432 0.865032 0.851546 0\n",
      "640 65141.5 0.803795 0.862236 0.848802 0\n",
      "660 64578.2 0.80031 0.859603 0.846216 0\n",
      "680 64039.0 0.796961 0.857118 0.843771 0\n",
      "700 63521.9 0.793738 0.854773 0.841453 0\n",
      "720 63025.2 0.790627 0.852556 0.839255 0\n",
      "740 62546.0 0.787613 0.850451 0.837164 0\n",
      "760 62082.3 0.784688 0.848453 0.83517 0\n",
      "780 61632.4 0.78184 0.846552 0.833266 0\n",
      "800 61194.9 0.779059 0.844741 0.831444 0\n",
      "820 60768.4 0.776339 0.843011 0.829694 0\n",
      "840 60351.9 0.773673 0.841354 0.828009 0\n",
      "860 59944.4 0.771056 0.839768 0.826387 0\n",
      "880 59545.0 0.768482 0.838246 0.824824 0\n",
      "900 59153.1 0.765948 0.836783 0.823316 0\n",
      "920 58768.1 0.76345 0.835375 0.821856 0\n",
      "940 58389.7 0.760989 0.834015 0.820438 0\n",
      "960 58018.0 0.758561 0.832699 0.819066 0\n",
      "980 57653.9 0.756177 0.831427 0.817729 0\n",
      "1000 57297.2 0.753832 0.83019 0.816422 0\n",
      "1020 56946.9 0.751524 0.828996 0.815158 0\n",
      "1040 56603.4 0.749254 0.827845 0.813932 0\n",
      "1060 56265.8 0.747016 0.826729 0.812742 0\n",
      "1080 55934.5 0.744812 0.825648 0.81158 0\n",
      "1100 55609.3 0.742644 0.824595 0.810444 0\n",
      "1120 55289.8 0.740507 0.823575 0.809333 0\n",
      "1140 54976.9 0.738408 0.822592 0.80825 0\n",
      "1160 54670.1 0.736343 0.821638 0.807192 1\n",
      "1180 54369.2 0.734314 0.820712 0.806163 0\n",
      "1200 54074.5 0.732321 0.819811 0.805155 1\n",
      "1220 53786.0 0.730364 0.818929 0.80417 0\n",
      "1240 53504.2 0.728446 0.818072 0.803208 1\n",
      "1260 53229.1 0.726572 0.817241 0.802265 0\n",
      "1280 52960.3 0.724734 0.816435 0.801347 1\n",
      "1300 52697.6 0.722933 0.815656 0.800457 0\n",
      "1320 52441.0 0.72117 0.814898 0.799591 1\n",
      "1340 52190.3 0.719443 0.814164 0.798748 0\n",
      "1360 51945.2 0.717753 0.813453 0.797927 1\n",
      "1380 51705.9 0.716096 0.812756 0.797128 0\n",
      "1400 51472.3 0.714476 0.812075 0.796352 1\n",
      "1420 51244.2 0.71289 0.811414 0.795598 0\n",
      "1440 51021.5 0.711339 0.810769 0.794868 1\n",
      "1460 50804.4 0.709825 0.810143 0.794156 0\n",
      "1480 50592.6 0.708342 0.809533 0.793464 1\n",
      "1500 50386.0 0.706894 0.808941 0.792797 0\n",
      "1520 50184.6 0.705479 0.808367 0.792152 1\n",
      "1540 49988.3 0.704098 0.807812 0.791526 0\n",
      "1560 49796.7 0.702748 0.807279 0.790922 1\n",
      "1580 49610.0 0.701427 0.806762 0.790336 0\n",
      "1600 49428.1 0.70014 0.806256 0.789767 1\n",
      "1620 49251.1 0.698886 0.805761 0.789216 0\n",
      "1640 49078.6 0.697658 0.805275 0.78868 1\n",
      "1660 48910.4 0.696462 0.804804 0.788161 2\n",
      "1680 48746.2 0.695292 0.804349 0.787655 0\n",
      "1700 48586.3 0.69415 0.80391 0.787163 1\n",
      "1720 48430.7 0.693036 0.803483 0.786692 2\n",
      "1740 48278.8 0.691949 0.803066 0.786235 0\n",
      "1760 48130.4 0.690885 0.802661 0.785792 1\n",
      "1780 47985.8 0.689845 0.80227 0.785359 2\n",
      "1800 47844.5 0.688829 0.801888 0.784936 0\n",
      "1820 47706.6 0.687834 0.801519 0.784526 1\n",
      "1840 47572.0 0.686863 0.801162 0.784121 2\n",
      "1860 47440.6 0.685913 0.800814 0.783725 0\n",
      "1880 47312.2 0.684984 0.800477 0.783342 1\n",
      "1900 47186.7 0.684076 0.800151 0.782975 2\n",
      "1920 47064.2 0.683186 0.799833 0.78262 0\n",
      "1940 46944.4 0.682316 0.799527 0.782276 1\n",
      "1960 46827.4 0.681466 0.799231 0.781942 2\n",
      "1980 46713.0 0.680632 0.798944 0.781617 3\n",
      "2000 46601.6 0.679818 0.798661 0.7813 0\n",
      "2020 46492.7 0.679023 0.798386 0.780991 1\n",
      "2040 46386.3 0.678245 0.798116 0.78069 2\n",
      "2060 46282.2 0.677483 0.797855 0.780396 3\n",
      "2080 46180.4 0.676737 0.797602 0.780113 0\n",
      "2100 46080.8 0.676007 0.797358 0.779835 1\n",
      "2120 45983.4 0.675291 0.797119 0.779564 2\n",
      "2140 45888.2 0.674592 0.796888 0.7793 3\n",
      "2160 45794.9 0.673906 0.796665 0.779045 4\n",
      "2180 45703.7 0.673234 0.796452 0.778798 0\n",
      "2200 45614.3 0.672575 0.79624 0.778557 1\n",
      "2220 45526.9 0.67193 0.796035 0.778324 2\n",
      "2240 45441.3 0.671298 0.795832 0.778098 3\n",
      "2260 45357.5 0.670678 0.795635 0.777876 4\n",
      "2280 45275.5 0.670073 0.795443 0.77766 0\n",
      "2300 45195.1 0.669476 0.795256 0.777449 1\n",
      "2320 45116.3 0.668893 0.795074 0.777243 2\n",
      "2340 45039.2 0.668321 0.794895 0.777042 3\n",
      "2360 44963.7 0.667759 0.794722 0.776846 4\n",
      "2380 44889.6 0.667209 0.794554 0.776655 5\n",
      "2400 44816.9 0.666668 0.794392 0.776469 0\n",
      "2420 44745.6 0.666137 0.794235 0.776284 1\n",
      "2440 44675.7 0.665615 0.794079 0.776101 2\n",
      "2460 44607.1 0.665104 0.793924 0.775921 3\n",
      "2480 44539.8 0.664602 0.793774 0.775748 4\n",
      "2500 44473.7 0.664108 0.793629 0.77558 5\n",
      "2520 44408.8 0.663623 0.793488 0.775414 6\n",
      "2540 44345.1 0.663147 0.793352 0.775254 0\n",
      "2560 44282.6 0.662678 0.79322 0.775097 1\n",
      "2580 44221.2 0.662219 0.793091 0.774943 2\n",
      "2600 44160.7 0.661767 0.792965 0.774793 3\n",
      "2620 44101.4 0.66132 0.792843 0.774648 4\n",
      "2640 44043.1 0.660883 0.792724 0.774506 5\n",
      "2660 43985.8 0.660454 0.792608 0.774368 6\n",
      "2680 43929.5 0.66003 0.792495 0.774235 7\n",
      "2700 43874.1 0.659614 0.792386 0.774107 8\n",
      "2720 43819.8 0.659205 0.792279 0.773979 0\n",
      "2740 43766.2 0.658803 0.792174 0.773855 1\n",
      "2760 43713.7 0.658406 0.792071 0.773734 2\n",
      "2780 43661.9 0.658016 0.79197 0.773616 3\n",
      "2800 43611.0 0.657633 0.791872 0.7735 4\n",
      "2820 43560.9 0.657254 0.791776 0.773389 5\n",
      "2840 43511.7 0.656882 0.791681 0.773279 6\n",
      "2860 43463.1 0.656515 0.791589 0.773172 7\n",
      "2880 43415.4 0.656155 0.7915 0.773067 8\n",
      "2900 43368.4 0.6558 0.791413 0.772963 9\n",
      "2920 43322.2 0.65545 0.79133 0.772862 10\n",
      "2940 43276.7 0.655106 0.791249 0.772764 0\n",
      "2960 43231.9 0.654766 0.791169 0.772669 1\n",
      "2980 43187.8 0.654432 0.791092 0.772577 2\n",
      "3000 43144.4 0.654102 0.791016 0.772487 3\n",
      "3020 43101.6 0.653777 0.790943 0.7724 4\n",
      "3040 43059.5 0.653458 0.790872 0.772315 5\n",
      "3060 43018.0 0.653143 0.790803 0.772231 6\n",
      "3080 42977.3 0.652834 0.790736 0.77215 7\n",
      "3100 42937.1 0.652529 0.790671 0.772071 8\n",
      "3120 42897.5 0.652227 0.790609 0.771993 9\n",
      "3140 42858.6 0.65193 0.790548 0.771918 10\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "minVR = 999\n",
    "not_change_n = 0\n",
    "for i in range(10001):\n",
    "    _, c, r, tr, vr = sess.run([training_step, cost, rmse, test_rmse, valid_rmse])\n",
    "    sess.run(clip)\n",
    "    if i%20 == 0:\n",
    "        print(i, c, r, vr, tr, not_change_n)\n",
    "    \n",
    "        if vr + 0.001 < minVR:\n",
    "            minVR = vr\n",
    "            not_change_n = 0\n",
    "        else:\n",
    "            not_change_n += 1\n",
    "\n",
    "        if not_change_n > 10:\n",
    "            break\n",
    "            \n",
    "    \n",
    "    \"\"\"\n",
    "    if i%500 == 0:\n",
    "        r, tr = sess.run([rmse, test_rmse])\n",
    "        #r = sess.run([rmse])\n",
    "        print(\"rmse:\", i, r, tr)\n",
    "    \"\"\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.51018739,  1.32544243,  0.75315642,  0.61326277,  0.50101417],\n",
       "       [ 0.76432943,  0.56661445,  1.06551993,  1.00206208,  0.66632766],\n",
       "       [ 1.23120642,  0.24411611,  0.5585928 ,  1.04360235,  0.95001435],\n",
       "       ..., \n",
       "       [ 0.6849981 ,  0.63989776,  0.65039289,  0.90525734,  0.69301009],\n",
       "       [ 1.12022388,  0.42086723,  0.71160662,  1.13876915,  0.83841908],\n",
       "       [ 1.0753845 ,  0.46342456,  0.8840068 ,  0.92568862,  0.7817139 ]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ws3.6",
   "language": "python",
   "name": "ws"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
